{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "TP_IMA206_flou.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBS_WMQfde0-"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat May 23 09:09:08 2020\n",
        "\n",
        "@author: said\n",
        "\"\"\"\n",
        "\n",
        "#%%% Inclusion de modules \n",
        "import numpy as np\n",
        "from skimage import io as skio\n",
        "import matplotlib.pyplot as plt\n",
        "import platform\n",
        "import tempfile\n",
        "import os\n",
        "import scipy.signal\n",
        "import time\n",
        "import numpy\n",
        "import math\n",
        "\n",
        "pi=np.pi\n",
        "atan2=math.atan2\n",
        "\n",
        "sin=np.sin\n",
        "cos=np.cos\n",
        "fft=np.fft.fft\n",
        "fft2=np.fft.fft2\n",
        "ifft2=np.fft.ifft2\n",
        "fftshift=np.fft.fftshift\n",
        "ifftshift=np.fft.ifftshift\n",
        "\n",
        "log=np.log\n",
        "real=np.real\n",
        "conj=np.conj \n",
        "atan2=math.atan2\n",
        "tan=np.tan\n",
        "fftshift=np.fft.fftshift"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_ahghAde1W"
      },
      "source": [
        "#%% SECTION de definition et d'imports a lancer au debut\n",
        "# Si vous êtes dans colab mettre colaboratory ET notebook a True\n",
        "# si vous êtes en local dans un notebook mettez colbaoratory a False\n",
        "#      et installez bokeh vous-même\n",
        "# Si vous utilisez le script sur une machine local non pas dans un notebook \n",
        "# mettez les deux à False \n",
        "notebook=True\n",
        "colaboratory=True\n",
        "if notebook:\n",
        "    from IPython.display import Audio\n",
        "    if colaboratory:\n",
        "        !pip install bokeh\n",
        "    from bokeh.plotting import figure, output_file, show\n",
        "    from bokeh.plotting import show as showbokeh\n",
        "    from bokeh.io import output_notebook\n",
        "    output_notebook()\n",
        "    from bokeh.colors import Color as bcolor\n",
        "    from bokeh.colors.rgb import RGB\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy \n",
        "from scipy.signal import lfilter\n",
        "import scipy.io\n",
        "import platform\n",
        "import time\n",
        "\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def RGBtoYCrCb(im,ty='8bit'): \n",
        "    assert len(im.shape)==3 and im.shape[2]==3, 'image dans un mauvais format'\n",
        "    if ty=='8bit':\n",
        "        delta=128 #ce delta est simplement le milieu de la plage des valeurs \n",
        "                    # possibles. \n",
        "    out=np.empty(im.shape)\n",
        "    Y=0.299*im[:,:,0]+0.587*im[:,:,1]+0.114*im[:,:,2]\n",
        "    Cr=(im[:,:,0]-Y)*0.713+delta\n",
        "    Cb=(im[:,:,2]-Y)*0.564+delta\n",
        "    return (Y,Cr,Cb)\n",
        "\n",
        "\n",
        "\n",
        "def YCrCbtoRGB(Y,Cr,Cb,ty='8bit'):\n",
        "    delta=128\n",
        "    out=np.empty([*Y.shape,3],dtype=np.float32)\n",
        "    out[:,:,0]=Y+1.402*(Cr-delta)\n",
        "    out[:,:,1]=Y-0.34414*(Cb-128)-0.71414*(Cr-128)\n",
        "    out[:,:,2]=Y+1.772*(Cb-128)\n",
        "    return out\n",
        "    \n",
        "import skimage.transform\n",
        "if notebook:\n",
        "  liste_couleurs_grises=[]\n",
        "  for k in range(256):\n",
        "    liste_couleurs_grises.append(RGB(k,k,k))\n",
        "  def affiche_pour_colab(im,normalise=True,MINI=0.0, MAXI=255.0,titre=''): #special colab, ne pas regarder\n",
        "    def normalise_image_pour_bokeh(X,normalise=True,MINI=0.0, MAXI=255.0,titre=''):\n",
        "      Y=(X.copy())\n",
        "      if len(Y.shape)==2: \n",
        "        Y=np.zeros((*Y.shape,3))\n",
        "        for k in range(3):\n",
        "          Y[:,:,k]=X.copy()\n",
        "   \n",
        "      if normalise:\n",
        "        Y-=Y.min()\n",
        "        Y/=Y.max()\n",
        "        Y*=255\n",
        "      else:\n",
        "        Y-=MINI\n",
        "        Y/=(MAXI-MINI)\n",
        "        Y*=255\n",
        "\n",
        "      Y=Y.astype(np.uint8)\n",
        "      sortie=np.empty(Y.shape[:2],dtype=np.uint32)\n",
        "      view=sortie.view(dtype=np.uint8).reshape((Y.shape[:2]+(4,)))\n",
        "      for k in range(3):\n",
        "        view[:,:,k]=Y[:,:,k]\n",
        "      view[:,:,3]=255\n",
        "      return sortie\n",
        "    img=normalise_image_pour_bokeh(np.flipud(im),normalise=normalise,MINI=MINI,MAXI=MAXI)# np.flipud(np.fliplr(im)))\n",
        "    p = figure(tooltips=[(\"x\", \"$x\"), (\"y\", \"$y\"), (\"value\", \"@image\")],title=titre)\n",
        "    p.x_range.range_padding = p.y_range.range_padding = 0\n",
        "\n",
        "    # must give a vector of images\n",
        "    p.image_rgba(image=[img],x=0,y=0, dw=im.shape[1], dh=im.shape[0])\n",
        "    showbokeh(p)\n",
        "\n",
        "  def affiche(im,normalise=True,MINI=0.0, MAXI=255.0,titre='',printname=False):\n",
        "      affiche_pour_colab(im,normalise=normalise,MINI=MINI, MAXI=MAXI,titre=titre) \n",
        "         # sous google colab beaucoup d''options disparaissent\n",
        "\n",
        "else:\n",
        "    def affiche(im,normalise=True,MINI=0.0, MAXI=255.0,titre='',printname=False):\n",
        "        \"\"\" Cette fonction fait afficher l'image EN NIVEAUX DE GRIS \n",
        "        dans gimp. Si un gimp est deja ouvert il est utilise.\n",
        "        Par defaut normalise=True. Et dans ce cas l'image est normalisee \n",
        "        entre 0 et 255 avant d'être sauvegardee.\n",
        "        Si normalise=False MINI et MAXI seront mis a 0 et 255 dans l'image \n",
        "        resultat\n",
        "        \"\"\"\n",
        "        imt=np.float32(im.copy())\n",
        "        if platform.system()=='Darwin': #on est sous mac\n",
        "            prephrase='open -a GIMP-2.10.app ' #certainement à adapter\n",
        "            endphrase=' ' \n",
        "        else: #SINON ON SUPPOSE LINUX (si vous avez un windows je ne sais comment \n",
        "                                   #faire. Si vous savez dites-moi.)\n",
        "            prephrase='gimp '\n",
        "            endphrase= ' &'\n",
        "    \n",
        "        if normalise:\n",
        "            m=imt.min()\n",
        "            imt=imt-m\n",
        "            M=imt.max()\n",
        "            if M>0:\n",
        "                imt=imt/M\n",
        "\n",
        "        else:\n",
        "            imt=(imt-MINI)/(MAXI-MINI)\n",
        "            imt[imt<0]=0\n",
        "            imt[imt>1]=1\n",
        "    \n",
        "        if titre!='':\n",
        "            titre='_'+titre+'_'\n",
        "        titre=titre.replace(' ','')\n",
        "        nomfichier=tempfile.mktemp('TPIMA'+titre+'.png')\n",
        "        commande=prephrase +nomfichier+endphrase\n",
        "        skio.imsave(nomfichier,imt)\n",
        "        os.system(commande)\n",
        "        if printname:\n",
        "            print(nomfichier)\n",
        "\n",
        "\n",
        "if notebook:\n",
        "    def plot(*argv):\n",
        "        if len(argv)==2:\n",
        "            x=argv[0]\n",
        "            y=argv[1]\n",
        "        elif (len(argv)==1):\n",
        "            x=np.arange(0,len(y))\n",
        "            y=argv[0]\n",
        "        else:\n",
        "            raise Exception(\"Erreur dans les graphiques: n'arriverait \\\n",
        "                pas hors de google colaboratory\")\n",
        "    \n",
        "        p=figure()\n",
        "        p.line(x,y)\n",
        "        showbokeh(p)\n",
        "    def stem(*argv):\n",
        "        if len(argv)==2:\n",
        "            x=argv[0]\n",
        "            y=argv[1]\n",
        "        elif len(argv)==1:\n",
        "            x=np.arange(0,len(y))\n",
        "            y=argv[0]\n",
        "        else:\n",
        "            raise Exception(\"Erreur dans les graphiques: \\\n",
        "                            n'arriverait pas hors de google colaboratory\")\n",
        "\n",
        "        p = figure()#title=\"simple line example\", x_axis_label='x',\n",
        "                    #y_axis_label='y')\n",
        "\n",
        "        # add a line renderer with legend and line thickness\n",
        "        p.segment(x,0,x, y, legend_label=\"Temp.\", line_width=2)\n",
        "\n",
        "        showbokeh(p)\n",
        "    def show():\n",
        "        return\n",
        "else:\n",
        "    plot=plt.plot\n",
        "    stem=plt.stem\n",
        "    show=plt.show # force l'affichage du graphique courant\n",
        "\n",
        "def norm(X):\n",
        "    return ((abs(X)**2).sum())**0.5\n",
        "def read_image(fi):\n",
        "    return np.float32(skio.imread(fi))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRtxKfxlde1s"
      },
      "source": [
        "#%% Importation des données suivant que l'on est dans un notebook ou sur la \n",
        "    # machine locale. \n",
        "#%rm images.tgz # decommentez cette ligne si je vous dis que j'ai uploadé de nouvelles images  \n",
        "if notebook:\n",
        "    !wget https://perso.telecom-paris.fr/ladjal/IMA206flou/images.tgz\n",
        "    !tar xvzf images.tgz\n",
        "    rep_images='./images_IMA206_flou/'\n",
        "else: #modifiez ce répertoire suivant l'endroit où vous avez mis les images \n",
        "    rep_images=\\\n",
        "    '/Users/said/Nextcloud_maison/Boulot/IMA206_flou/images_IMA206_flou/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEO3mU8qde19"
      },
      "source": [
        "#%% FONCTIONS POUR LA DECONVOLUTION TV\n",
        "#NOTE dórganisation de mon code: CECI EST UNE COPIE D'UN FICHIER  TVdeconv.py\n",
        "\n",
        "def pad_image(im,pad=10):\n",
        "    out=np.zeros((im.shape[0]+2*pad,im.shape[1]+2*pad))\n",
        "    out[pad:-pad,pad:-pad]=im\n",
        "    for k in range(pad):\n",
        "        out[k,pad:-pad]=im[0,:]\n",
        "        out[-k-1,pad:-pad]=im[-1,:]\n",
        "        out[pad:-pad,k]=im[:,0]\n",
        "        out[pad:-pad,-k-1]=im[:,-1]\n",
        "    out[:pad,:pad]=im[0,0]\n",
        "    out[-pad:,:pad]=im[-1,0]\n",
        "    out[:pad,-pad:]=im[0,-1]\n",
        "    out[-pad:,-pad:]=im[-1,-1]\n",
        "    return out\n",
        "\n",
        "def unpad_image(im,pad=10):\n",
        "    return im[pad:-pad,pad:-pad].copy()\n",
        "\n",
        "def Fourier_kernel(K,s):\n",
        "    assert K.shape[0]%2==1 and K.shape[1]%2==1, \"Taille de noyau non impaire\"\n",
        "    Kf=np.zeros(s)\n",
        "    Ky,Kx=K.shape\n",
        "    Kx2=Kx//2\n",
        "    Ky2=Ky//2\n",
        "    Kf[:Ky2+1,:Kx2+1]=K[Ky2:,Kx2:]\n",
        "    Kf[:Ky2+1,-Kx2:]=K[Ky2:,:Kx2]\n",
        "    Kf[-Ky2:,:Kx2+1]=K[:Ky2,Kx2:]\n",
        "    Kf[-Ky2:,-Kx2:]=K[:Ky2,:Kx2]\n",
        "    return fft2(Kf)\n",
        "\n",
        "def taper_image(I,K): \n",
        "    \"\"\" Floute une image I par le noyau K (circulairement) cela donne une image J\n",
        "    On mélange l'image I avec l'image J de manière à ce que J soit prépondérente aux bords.\n",
        "    L'image J, lorsqu'on la déconle par le noyau K n'aura pas d'effets de bord. \"\"\"\n",
        "    kh,kw=K.shape\n",
        "    Ih,Iw=I.shape\n",
        "    wx=np.ones((Ih,Iw),dtype=np.float32)\n",
        "    wy=np.ones((Ih,Iw),dtype=np.float32)\n",
        "    X,Y=np.meshgrid(np.arange(0,Iw),np.arange(0,Ih))\n",
        "    wy[:kh,:]=sin(Y[:kh,:]*pi/(2*kh-1))**2\n",
        "    wy[-kh:,:]=sin((Ih-Y[-kh:,:])*pi/(2*kh-1))**2\n",
        "    wx[:,:kw]=sin(X[:,:kw]*pi/(2*kh-1))**2\n",
        "    wx[:,-kw:]=sin((Iw-X[:,-kw:])*pi/(2*kh-1))**2\n",
        "    fK=Fourier_kernel(K,I.shape)\n",
        "    J=real(ifft2(fft2(I)*fK))\n",
        "    out=J*(1-wx*wy)+I*(wx*wy)\n",
        "    return out\n",
        "\n",
        "def conv(im,K,Fourierform=False):\n",
        "    if not Fourierform:#on recoit les formes spatiales\n",
        "        Kf=Fourier_kernel(K,im.shape)\n",
        "        imf=fft2(im)\n",
        "        return np.real(ifft2(imf*Kf))\n",
        "    else:# forme Fourier\n",
        "        return np.real(ifft2(im*K))\n",
        "\n",
        "def champ_grad(u):#gradient circulaire\n",
        "    return np.stack((np.c_[(u[:,0]-u[:,-1]).reshape(-1,1),u[:,1:]-u[:,:-1]],\\\n",
        "             np.r_[(u[0,:]-u[-1,:]).reshape(1,-1),u[1:,:]-u[:-1,:]]))\n",
        "\n",
        "def universal_dot(X,Y):\n",
        "    return (X*Y).sum()\n",
        "\n",
        "def div_champ(c):\n",
        "    return np.c_[c[0,:,1:]-c[0,:,:-1],(c[0,:,0]-c[0,:,-1]).reshape(-1,1)]+\\\n",
        "            np.r_[c[1,1:,:]-c[1,:-1,:],(c[1,0,:]-c[1,-1,:]).reshape(1,-1)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def d_sub_problem(u,b,gamma=5/255):\n",
        "    gradu=champ_grad(u)\n",
        "    champ=gradu+b\n",
        "    s=champ.shape[1:]\n",
        "    no=(champ**2).sum(axis=0)**0.5\n",
        "    mask=(no<(1/gamma))\n",
        "    no[mask]=0.001\n",
        "    no=no.reshape(1,*s)\n",
        "    mu=1-1/(gamma*no)\n",
        "    champ*=mu\n",
        "    champ[:,mask]=0\n",
        "    #champ[1,mask]=0\n",
        "    return champ    \n",
        "\n",
        "def u_sub_problem(f,d,b,K,lamb,gamma=5,Fourierform=False,fdenom=None):\n",
        "    \"\"\" si Fourierform=True alors f et K sont donnees sous forme Fourier\"\"\"\n",
        "    if not Fourierform:\n",
        "        ff=fft2(f)\n",
        "        Kf=Fourier_kernel(K,f.shape)\n",
        "    else:\n",
        "        ff=f\n",
        "        Kf=K\n",
        "    if fdenom is None:\n",
        "        Kl=np.zeros(f.shape)\n",
        "        Kl[0,0]=4\n",
        "        Kl[0,1]=-1\n",
        "        Kl[1,0]=-1\n",
        "        Kl[-1,0]=-1\n",
        "        Kl[0,-1]=-1\n",
        "        fdenom=real(fft2(Kl))\n",
        "        fdenom+=(lamb/gamma)*(abs(Kf)**2)\n",
        "\n",
        "    numer=conj(Kf)*ff*(lamb/gamma)-fft2(div_champ(d-b))\n",
        "    return real(ifft2((numer)/fdenom))\n",
        "\n",
        "def sym_image(x):\n",
        "    out=np.concatenate((x,np.fliplr(x)),axis=1)\n",
        "    out=np.concatenate((out,np.flipud(out)),axis=0) #symetrise l'image\n",
        "    return out\n",
        "\n",
        "def TV(im):\n",
        "    g=champ_grad(im)\n",
        "    n=((g**2).sum(axis=0))**0.5\n",
        "    return n.sum()\n",
        "\n",
        "def fonctionnelle(f,u,K,d,b,lamb,gamma=5):\n",
        "    v1=TV(u)+lamb/2*norm(f-conv(f,K))**2\n",
        "    v2=v1+gamma/2*norm(d-champ_grad(u)-b)**2\n",
        "    return (v1,v2)\n",
        "\n",
        "def norm(X):\n",
        "    return ((X**2).sum())**0.5\n",
        "\n",
        "def TVdeconv(im,K,lamb,nbit=140,gamma=5/255,edgehandle='taper'):\n",
        "    \"\"\"\n",
        "    Si edgehandle= 'taper' alors on ajoute à l'image une bordure lisse\n",
        "    Si edgehandle= 'sym' alors on symmetrise l'image \n",
        "    Si edgehandle= 'nothing' alors on ne fait rien (mauvais)\n",
        "    \"\"\"\n",
        "    if edgehandle=='taper':\n",
        "        f=taper_image(pad_image(im,K.shape[0]),K)\n",
        "    elif edgehandle=='sym':\n",
        "        f=sym_image(im)\n",
        "    else:\n",
        "        f=im.copy()\n",
        "    s=f.shape\n",
        "    Kf=Fourier_kernel(K,s)\n",
        "    Kl=np.zeros(f.shape)\n",
        "    Kl[0,0]=4\n",
        "    Kl[0,1]=-1\n",
        "    Kl[1,0]=-1\n",
        "    Kl[-1,0]=-1\n",
        "    Kl[0,-1]=-1\n",
        "    fdenom=real(fft2(Kl))\n",
        "    fdenom+=lamb/gamma*(abs(Kf)**2)\n",
        "    u=np.zeros(s)\n",
        "    unew=np.zeros(s)\n",
        "    d=np.zeros((2,*s))\n",
        "    b=np.zeros((2,*s))\n",
        "    tol=norm(f)/1000\n",
        "    counter=0\n",
        "    ff=fft2(f)\n",
        "    #Kfff=conj(Kf)*ff*(lamb/gamma)\n",
        "    #print(\"iteration\",counter,' Fonctionnelles=',\\\n",
        "     #         fonctionnelle(f,unew,K,d,b,lamb))\n",
        "\n",
        "    while counter==0 or (norm(unew-u)>(0*tol-1) and counter<nbit):\n",
        "        counter+=1\n",
        "        u=unew\n",
        "        d=d_sub_problem(u, b,gamma=gamma)\n",
        "        \n",
        "        unew=u_sub_problem(ff, d, b, Kf, lamb,gamma=gamma,\\\n",
        "                           Fourierform=True,fdenom=fdenom)\n",
        "        b+=(champ_grad(unew)-d)\n",
        "        #print(\"iteration\",counter,)#' Fonctionnelles=',\\\n",
        "         #     fonctionnelle(f,unew,K,d,b,lamb))\n",
        "    \n",
        "    if edgehandle=='taper':\n",
        "        out=unpad_image(unew,K.shape[0])\n",
        "    elif edgehandle=='sym':\n",
        "        out=unew[:im.shape[0],:im.shape[1]]\n",
        "    else:\n",
        "        out=unew\n",
        "\n",
        "    return out\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIKONKcnde2K"
      },
      "source": [
        "# Pour tester la deconvolution par variation totale\n",
        "Vous testerez en particulier ce qui se passe quand on change le paramètre d'attache aux données $\\lambda$. \n",
        "Aussi, dire ce qui se passe si on se trompe de noyau.\n",
        "Quelles sont les possibilités de gestion des effets de bord? En particulier comment fonction la gestion \"taper\"?\n",
        "Comment le bruit influe-t-il sur le résultat? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7YsDwfDde2O"
      },
      "source": [
        "#%% test deconvolution \n",
        "t=15\n",
        "K=np.zeros((t,t))\n",
        "Mh=4*t+1 #taille du spectre\n",
        "for k in range(t):\n",
        "    K[k,k]=1\n",
        "    if k>0:\n",
        "        K[k,k-1]=1\n",
        "    if k<t-1:\n",
        "        K[k,k+1]=1\n",
        "K/=K.sum()\n",
        "im=read_image(rep_images+'lena.png')\n",
        "imconv=scipy.signal.convolve2d(im, K,mode='same',boundary='symm')\n",
        "deconv=TVdeconv(imconv,K,2000/255)\n",
        "affiche(imconv)\n",
        "affiche(deconv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwgJTbBrde2d"
      },
      "source": [
        "#%% SinglePhase Retrieval\n",
        "    # Cet algorithme essaye de trouver un noyau seulement en se \n",
        "# basant sur la densité de puissance de celui-ci\n",
        "# Partie SINGLEPHASE_RETRIEVAL\n",
        "def get_phase_alea(Mh,s=None):\n",
        "    if s is None:\n",
        "        s=Mh\n",
        "    im=np.random.randn(Mh,Mh)\n",
        "    #im[s:,:]=0\n",
        "    #im[:,s:]=0\n",
        "    return np.angle(np.fft.fft2(im))\n",
        "\n",
        "def from_module_phase(module,phase):\n",
        "    return np.real(np.fft.ifft2(module*np.exp(np.complex(0,1)*phase)))\n",
        "\n",
        "def SinglePhaseRetrieval(module,s,Mh=32,alpha=0.95,beta0=0.75,Ninner=300,known=None):\n",
        "    fft2=np.fft.fft2\n",
        "    ifft2=np.fft.ifft2\n",
        "    phg=get_phase_alea(Mh,s)\n",
        "    modg=module\n",
        "    \n",
        "    if known is None:\n",
        "        known=np.ones((Mh,Mh))>0\n",
        "    unknown=(np.vectorize(lambda x: not x))(known)\n",
        "    modg[unknown]=0\n",
        "    g=from_module_phase(modg,phg)\n",
        "    \n",
        "    for m in range(Ninner):\n",
        "        \n",
        "        beta=beta0+(1-beta0)*(1-np.exp(-(m/7)**3))\n",
        "        module_for_reconst=modg.copy()\n",
        "        module_for_reconst[known]=(alpha*module+(1-alpha)*modg)[known]\n",
        "        gp=from_module_phase(module_for_reconst,phg)\n",
        "        mask=(2*gp<g)\n",
        "        mask[s:,:]=True\n",
        "        mask[:,s:]=True\n",
        "        g[mask]=beta*g[mask]+(1-2*beta)*gp[mask]\n",
        "        invmask=(np.vectorize(lambda x: not x))(mask)\n",
        "        g[invmask]=gp[invmask]\n",
        "        fg=fft2(g)\n",
        "        phg=np.angle(fg)\n",
        "        modg=abs(fg)\n",
        "    g[g<0]=0\n",
        "    g[s:,:]=0\n",
        "    g[:,s:]=0\n",
        "    g=g/g.sum()\n",
        "    g[g<(1/255)]=0\n",
        "    g/=g.sum()\n",
        "    return g[:s,:s]\n",
        "        \n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFSNCNyzde2q"
      },
      "source": [
        "# Cellule pour tester le singlphase retrieval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oFKsvxHde2s"
      },
      "source": [
        "t=15\n",
        "K=np.zeros((t,t))\n",
        "Mh=4*t+1 #taille du spectre\n",
        "for k in range(t):\n",
        "    K[k,k]=1\n",
        "    if k>0:\n",
        "        K[k,k-1]=1\n",
        "    if k<t-1:\n",
        "        K[k,k+1]=1\n",
        "K/=K.sum()\n",
        "    \n",
        "HK=abs(fft2(K,(Mh,Mh))) #on calcule un spectre de taille Mh,Mh\n",
        "Ktilde=SinglePhaseRetrieval(HK,t,Mh=Mh)\n",
        "affiche(K, titre='vrai_noyau')\n",
        "affiche(Ktilde,titre='noyau_estime')\n",
        "#avec erreur de spectre\n",
        "HKm=HK.mean()\n",
        "HKbruit=(HK+(np.random.rand(Mh,Mh)-0.5)*HKm/2).clip(min=0)\n",
        "Ktildebr=SinglePhaseRetrieval(HKbruit,t,Mh=Mh)\n",
        "\n",
        "affiche(Ktildebr,titre='noyau_estime_avec_bruit')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O2L6kv2de23"
      },
      "source": [
        "#%% FONCTIONS CENTRALES DE L'ESTIMATION DU NOYAU DE FLOU\n",
        "    # Créées suivant <https://www.ipol.im/pub/art/2018/211/>\n",
        "def Dx_Dy(im):\n",
        "    \"\"\" Renvoie deux images de la même taille que im. im est une image en \n",
        "    niveaux de gris. \n",
        "    Ce sont les dérivées suivant x et suivant y en utilisant le noyau \n",
        "    dérivateur spécial \"\"\"\n",
        "    d=np.asarray([3,-32,168,-672,0,672,-168,32,-3])/840\n",
        "    d=d.reshape((1,-1))\n",
        "    Dx=scipy.signal.convolve2d(im, d,mode='same',boundary='symm')\n",
        "    Dy=scipy.signal.convolve2d(im, d.T,mode='same',boundary='symm')\n",
        "    return (Dx,Dy)\n",
        "\n",
        "\n",
        "def entre_Mpi2_pi2(x):\n",
        "    pi=np.pi\n",
        "    y=x%pi\n",
        "    if y>=pi/2:\n",
        "        y-=pi\n",
        "    return y\n",
        "    \n",
        "def liste_thetas_depuis_spectre(N): \n",
        "    \"\"\" Renvoies la liste des thetas telles que pour tout point du \n",
        "    spectre discret de taille NxN corresponde un angle\"\"\"\n",
        "    if N%2==0:\n",
        "        tmp=np.concatenate((np.arange(0,N//2+1),np.arange(-N//2+1,0)))\n",
        "    else:\n",
        "        tmp=np.concatenate((np.arange(0,(N+1)//2),np.arange(-(N-1)//2,0)))\n",
        "    tmp=tmp.astype(np.int)\n",
        "    X,Y=np.meshgrid(tmp,tmp) # carte des fréquences \n",
        "    pi=np.pi\n",
        "    Xs=X.reshape(-1)\n",
        "    Ys=Y.reshape(-1)\n",
        "    lt=[]\n",
        "    c=0\n",
        "    for k in range(len(Xs)):\n",
        "        if Xs[k]>=0 and np.gcd(Xs[k],Ys[k])==1:\n",
        "            c+=1\n",
        "            an=math.atan2(Ys[k],Xs[k])\n",
        "            lt.append(entre_Mpi2_pi2(an))\n",
        "    lt=np.asarray(list(set(lt))) #unique\n",
        "    lt=np.sort(lt)\n",
        "    surech=0*lt\n",
        "    for k in range(len(lt)):\n",
        "        an=lt[k]\n",
        "        if abs(an)<pi/4:\n",
        "            surech[k]=1/cos(abs(an))\n",
        "        else:\n",
        "            surech[k]=1/sin(abs(an))\n",
        "    return lt,surech\n",
        "\n",
        "def projections_rapide_shear(tab,thetas,demitaille): \n",
        "    \"\"\" projette tab sur toutes les droites d'angles dans thetas.\n",
        "    La sortie est centree autour de la projection du point central de l'image.\n",
        "    Nous faisons la projection shear: c'est à dire pas la projection orthogonale\n",
        "    Cela respecte la méthode originale dans l'article \n",
        "    Les angles sont censés être entre -pi/2 et pi/2\n",
        "    Mais leur ordre importe peu.\n",
        "    \"\"\"\n",
        "    \n",
        "    L=len(thetas)\n",
        "    cs=cos(thetas)\n",
        "    ss=sin(thetas)\n",
        "    ccs=cs.copy()\n",
        "    css=ss.copy()\n",
        "    # modification pour tenir compte du shear\n",
        "    for m in range(len(thetas)):\n",
        "        t=(thetas[m])\n",
        "        if abs(t)<=pi/4:\n",
        "            ccs[m]=1\n",
        "            css[m]=tan(t)\n",
        "        else:\n",
        "            css[m]=1\n",
        "            ccs[m]=cos(t)/sin(t)\n",
        "        \n",
        "            \n",
        "    M,N=tab.shape\n",
        "    T=M+N+4\n",
        "    #le pixel central tombe toujours au même endroit\n",
        "    poscentre=(T)//2\n",
        "    kc=M//2\n",
        "    lc=N//2\n",
        "    out=np.zeros((L,T))\n",
        "    outs1=out.reshape(-1)\n",
        "    vals=np.zeros(L)\n",
        "    Ls=(T*np.arange(0,L)).astype(np.int)\n",
        "    for k in range(M):\n",
        "        print(k/M*100,'%',end='\\r')\n",
        "        for l in range(N):\n",
        "            pos=np.round(ccs*(l-lc)+css*(k-kc)).astype(np.int)+poscentre\n",
        "            if max(pos)>T:\n",
        "                print('offenders',k,l)\n",
        "            vals[:]=tab[k,l]\n",
        "            outs1[Ls+pos]+=vals\n",
        "    return (out[:,poscentre-demitaille:poscentre+demitaille+1])\n",
        "\n",
        "def projections_rapide_gradient_shear(DDx,DDy,DDxy,DDyx,thetas,demitaille): \n",
        "    \"\"\" utile les intercorralations de Dx,Dy avec eux même pour calculer \n",
        "    les projections des autocorrelations du noyau \n",
        "    \"\"\"\n",
        "    \n",
        "    L=len(thetas)\n",
        "    cs=cos(thetas)\n",
        "    ss=sin(thetas)\n",
        "    cs2=cs**2\n",
        "    ss2=ss**2\n",
        "    csss=cs*ss\n",
        "    ccs=cs.copy()\n",
        "    css=ss.copy()\n",
        "    # modification pour tenir compte du shear\n",
        "    for m in range(len(thetas)):\n",
        "        t=thetas[m]\n",
        "        if abs(t)<=pi/4:\n",
        "            ccs[m]=1\n",
        "            css[m]=tan(t)\n",
        "        else:\n",
        "            css[m]=1\n",
        "            ccs[m]=cos(t)/sin(t)\n",
        "        \n",
        "            \n",
        "    M,N=DDx.shape\n",
        "    T=M+N+4\n",
        "    #le pixel central tombe toujours au même endroit\n",
        "    poscentre=(T)//2\n",
        "    kc=M//2\n",
        "    lc=N//2\n",
        "\n",
        "    out=np.zeros((L,T))\n",
        "    outs1=out.reshape(-1)\n",
        "    vals=np.zeros(L)\n",
        "    Ls=(T*np.arange(0,L)).astype(np.int)\n",
        "    for k in range(M):\n",
        "        print(k/M*100,'%',end='\\r')\n",
        "        for l in range(N):\n",
        "            pos=np.round(ccs*(l-lc)+css*(k-kc)).astype(np.int)+poscentre\n",
        "            if max(pos)>T-1:\n",
        "                print('offenders',k,l)\n",
        "            #print(\"debug\", k,l,DDx.shape)\n",
        "            vals[:]=cs2*DDx[k,l]+ss2*DDy[k,l]+csss*(DDxy[k,l]+DDyx[k,l])\n",
        "            #if vals[0]!=DDy[k,l]:\n",
        "            #    print('Houston we have a problem',k,l,vals[0],DDy[k,l],cs2[0],ss2[0],csss[0])\n",
        "            outs1[Ls+pos]+=vals\n",
        "    return (out[:,poscentre-demitaille:poscentre+demitaille+1])\n",
        "\n",
        "def next_power_2(T):# renvoie la puissance de deux immédiatement supérieure \n",
        "    return int(2**(np.floor(np.log(T)/np.log(2))+1))\n",
        "\n",
        "def decoupe(X,A): #decoupe une partie de tableau et la fftshift\n",
        "    out1=np.concatenate((X[:A+1,-A:],X[:A+1,:A+1]),axis=1)\n",
        "    out2=np.concatenate((X[-A:,-A:],X[-A:,:A+1]),axis=1)\n",
        "    out=np.concatenate((out2,out1),axis=0)\n",
        "    return out\n",
        "def calcul_correlations_initiales(img,thetas,p):\n",
        "    \"\"\" estime l'autocorrelation du noyau à partir du gradient de l'image\n",
        "    La deconvolution et le filtrage median sont fait ailleurs\"\"\"\n",
        "    \n",
        "    \n",
        "    \n",
        "    (Dx,Dy)=Dx_Dy(img)\n",
        "    # calcul des trois correlations\n",
        "    (a,b)=Dx.shape\n",
        "    A=next_power_2(2*a)\n",
        "    B=next_power_2(2*b)\n",
        "    fDx=fft2(Dx,(A,B))\n",
        "    fDy=fft2(Dy,(A,B))\n",
        "    DDx=real(ifft2(abs(fDx)**2))\n",
        "    DDy=real(ifft2(abs(fDy)**2))\n",
        "    DDxy= real(ifft2(fDx*conj(fDy)))\n",
        "    DDyx= real(ifft2(fDy*conj(fDx)))\n",
        "    DDx=decoupe(DDx,2*p)\n",
        "    DDy=decoupe(DDy,2*p)\n",
        "    DDxy=decoupe(DDxy,2*p)\n",
        "    DDyx=decoupe(DDyx,2*p)\n",
        "\n",
        "    \n",
        "    out=projections_rapide_gradient_shear(DDx,DDy,DDxy,DDyx,thetas,2*p)\n",
        "    return out\n",
        "\n",
        "\n",
        "def deconv_intrinsic_blur(corr,alpha=2.1):\n",
        "    \"\"\" Deconvole l'autocorrelation de la projection par un flou\n",
        "    minimal dû à l'optique. \"\"\"\n",
        "    _,qp1=corr.shape\n",
        "    M=np.zeros((qp1,qp1))\n",
        "    for k in range(qp1):\n",
        "        for l in range(qp1):\n",
        "            M[k,l]=1/((abs(k-l)+1)**alpha)\n",
        "    M/=M[0,:].sum()\n",
        "    M=np.linalg.inv(M)\n",
        "    deconvbrute=(M@corr.T).T\n",
        "    print('shape de deconvbrut', deconvbrute.shape)\n",
        "    poscentre=qp1//2\n",
        "    for k in range(deconvbrute.shape[0]):\n",
        "        if (deconvbrute[k,poscentre-2:poscentre+2].min())<0:\n",
        "            print('failure of deconv', k,poscentre,deconvbrute[k,poscentre-2:poscentre+2] )\n",
        "            deconvbrute[k]=corr[k]\n",
        "    return deconvbrute\n",
        "    \n",
        "    \n",
        "def initial_support_estimation(tab_corrs,centre,thetas,kappa=30):\n",
        "    tab_interet=tab_corrs[:,centre:]\n",
        "    sprime=tab_interet.argmin(axis=1)            \n",
        "    s=(tab_interet.shape[1]-1)*np.ones(tab_interet.shape[0])\n",
        "    for k in range(tab_interet.shape[0]):\n",
        "        if sprime[k]<s[k]:\n",
        "            s[k]=sprime[k]\n",
        "            for m in range(tab_interet.shape[0]):\n",
        "                s[m]=min(s[m],\\\n",
        "                                   sprime[k]+\\\n",
        "                                       kappa*abs(thetas[m]-thetas[k]))\n",
        "    return s\n",
        "\n",
        "def Estimate_h_correlations(tab_corrs,supports):\n",
        "    \"\"\" si le support est connu, on met à zéro tout ce qui dépasse. \n",
        "       on enleve R[s] à tout le monde \n",
        "       on normalise à somme 1\"\"\"\n",
        "    centre=tab_corrs.shape[1]//2\n",
        "    new_corrs=tab_corrs.copy()\n",
        "    for k in range(new_corrs.shape[0]):\n",
        "        sint=int(np.round(supports[k]))\n",
        "        new_corrs[k,:]-=new_corrs[k,centre+sint]\n",
        "        new_corrs[k,:centre-sint+1]=0\n",
        "        new_corrs[k,centre+sint:]=0\n",
        "        new_corrs[new_corrs<0]=0\n",
        "        new_corrs[k,:]/=(new_corrs[k,:]).sum()\n",
        "    # filtrage median circulaire\n",
        "    taille=int(np.ceil(new_corrs.shape[0]**0.5)) \n",
        "    out=np.zeros(new_corrs.shape)\n",
        "    #taille=0 # supprier le filtrage\n",
        "    for k in range(new_corrs.shape[0]):\n",
        "        if k-taille<0:\n",
        "            tabmed=np.concatenate((new_corrs[:k+taille,:],new_corrs[k-taille:,:]),axis=0)\n",
        "        elif k+taille+1>new_corrs.shape[0]:\n",
        "            tabmed=np.concatenate((new_corrs[k-taille:,:],\\\n",
        "                                   new_corrs[:((k+taille+1)%new_corrs.shape[0]),:]),axis=0)\n",
        "        else:\n",
        "            tabmed=new_corrs[k-taille:k+taille+1,:]\n",
        "        out[k,:]=np.median(tabmed,axis=0)\n",
        "    return out\n",
        "\n",
        "\n",
        "def Restimation_supports_noyau(h,p,thetas,ratio=0.05):\n",
        "    \"\"\"recalcule les autocorrelations \n",
        "    du noyau a partir d'une nouvelle estiation et recalcule les supports\"\"\"\n",
        "    \n",
        "    (a,b)=h.shape\n",
        "    A=next_power_2(2*a+1)\n",
        "    B=next_power_2(2*b+1)\n",
        "    fh=fft2(h,(A,B))\n",
        "    autocor=real(ifft2(abs(fh)**2))\n",
        "    autocor=decoupe(autocor,p)\n",
        "    #affiche(autocor)\n",
        "    \n",
        "    proj=projections_rapide_shear(autocor,thetas,p)\n",
        "    #affiche(proj)\n",
        "    centre=p\n",
        "    idxs=np.arange(p+1)\n",
        "    out=np.zeros(thetas.shape[0])\n",
        "    for k in range(proj.shape[0]):\n",
        "        ma=proj[k].max()\n",
        "        mask=proj[k,centre:]>(ratio*ma)\n",
        "        out[k]=(idxs*mask).max()\n",
        "    return out\n",
        "   \n",
        "\n",
        "def calcul_indices_passage_corr_power_spectrum_kernel(N,sc,thetas):\n",
        "    \"\"\"Calcule des indices tels que \n",
        "     f=fft_corr[indices] \n",
        "     donnera dans f le power spectrum de taille NxN en shape (-1) \n",
        "     du noyau. fft_corr est la trasnformée de Fourier des correlations\n",
        "     (en shape(-1)).\n",
        "     sc est un couple \n",
        "     thetas sont les angles choisis pour la correlation \n",
        "     Ce calcul d'indices est fait une fois pour toute pour tous les calculs. \n",
        "     N : fft2 du noyau doit etre de forme carree NxN\n",
        "    \"\"\"   \n",
        "\n",
        "     \n",
        "    _,w=sc\n",
        "\n",
        "    if N%2==0:\n",
        "        tmp=np.concatenate((np.arange(0,N//2+1),np.arange(-N//2+1,0)))\n",
        "    else:\n",
        "        tmp=np.concatenate((np.arange(0,(N+1)//2),np.arange(-(N-1)//2,0)))\n",
        "    [XX,YY]=np.meshgrid(tmp/N,tmp/N) # les frequences\n",
        "    #angle=np.empty(XX.shape,dtype=np.float32)\n",
        "    numligne=np.empty(XX.shape,dtype=np.int)\n",
        "    posdansligne=np.empty(XX.shape,dtype=np.int)\n",
        "    indexs=np.zeros(N*N,dtype=np.int)\n",
        "    for k in range(XX.shape[0]):\n",
        "        for l in range(XX.shape[1]):\n",
        "            angle=entre_Mpi2_pi2( atan2(YY[k,l],XX[k,l])) \n",
        "            #if angle<-pi/2:\n",
        "            #    angle+=pi\n",
        "            #elif angle>pi/2:\n",
        "            #    angle-=pi    \n",
        "            numligne[k,l]=abs(thetas-angle).argmin()\n",
        "            #if abs(thetas-angle).min()>0.001:\n",
        "            #    print ('probleme')\n",
        "            d=(XX[k,l]**2+YY[k,l]**2)**0.5\n",
        "            if abs(thetas[numligne[k,l]])<pi/4:\n",
        "                maxd=1/cos(abs(thetas[numligne[k,l]]))\n",
        "            else:\n",
        "                maxd=1/sin(abs(thetas[numligne[k,l]]))\n",
        "            posdansligne[k,l]=min(int(np.round(d/maxd*w)),w//2)\n",
        "        \n",
        "            indexs[k*N+l]=numligne[k,l]*w+posdansligne[k,l]\n",
        "    return indexs,numligne,posdansligne\n",
        "\n",
        "def spectre_puissance_depuis_corrs(tab_corrs,N,indexs):\n",
        "    \"\"\" transforme des correlations en un spectre de puissance \n",
        "    utilise des indices precalcules\"\"\"\n",
        "    #zero padding\n",
        "    h,w=tab_corrs.shape\n",
        "    center=(w-1)//2\n",
        "    tmp=np.zeros((h,N))\n",
        "    tmp[:,:center+1]=tab_corrs[:,center:]\n",
        "    tmp[:,-center:]=tab_corrs[:,:center]\n",
        "    out=np.zeros((N,N))\n",
        "    fcorr=fft(tmp)\n",
        "    #print(norm(np.imag(fcorr))/norm(fcorr))\n",
        "    outs1=out.reshape(-1)\n",
        "    fcorrs1=fcorr.reshape(-1)\n",
        "    outs1[:]=np.real(fcorrs1[indexs])\n",
        "    outs1[outs1<0]=0 #Les puissances sont négatives\n",
        "    return(out)\n",
        "\n",
        "def convol_carre(im,taille):\n",
        "    \"\"\"covole tres rapidement contre un carre\"\"\"\n",
        "    im=im.cumsum(axis=0)\n",
        "    im=im[taille:,:]-im[:-taille,:]\n",
        "    im=im.cumsum(axis=1)\n",
        "    im=im[:,taille:]-im[:,:-taille]\n",
        "    return im\n",
        "\n",
        "def calcul_variances_patchs(img,taille):\n",
        "    \"\"\"Renvoie une image des variances des patchs de taille=taille X taille \n",
        "    La sortie de cette fonction permet de trouver dez petites zones dans \n",
        "    l'image sur lesquels tester la deconvolution\"\"\"\n",
        "    imgmoy=convol_carre(img,taille)/(taille**2)\n",
        "    imgvar=convol_carre(img**2,taille)\n",
        "    imgvar=imgvar-(imgmoy**2)*(taille**2)\n",
        "    return imgvar\n",
        "\n",
        "def Propose_patch_haute_variance(Varianceimage,img,taille):\n",
        "    h,w=Varianceimage.shape\n",
        "    xs=np.random.randint(0,high=w,size=10)\n",
        "    ys=np.random.randint(0,high=h,size=10)\n",
        "    pos=Varianceimage.reshape(-1)[xs+ys*w].argmax()\n",
        "    print(xs[pos],ys[pos])\n",
        "    return img[ys[pos]:ys[pos]+taille,xs[pos]:xs[pos]+taille].copy()\n",
        "\n",
        "def score_restau(im): # utilisée pour comparer des resultats de deconvolution \n",
        "    # entre eux. \n",
        "    dx=im[:-1,1:]-im[:-1,:-1]\n",
        "    dy=im[1:,:-1]-im[:-1,:-1]\n",
        "    n=((dx**2)+(dy**2))**0.5\n",
        "    return n.sum()/(((n**2).sum())**0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfiqQstWde3D"
      },
      "source": [
        "#%% La fonction principale qui utilise toutes les composantes précédentes\n",
        "def estime_noyau(img,p=25,lamb=1500/255,Nouter=3,Ntries=30,Ninner=300,\\\n",
        "                 verbose=True):\n",
        "    t0=time.time()\n",
        "    taille_patch=150\n",
        "    imgvars=calcul_variances_patchs(img,taille_patch)\n",
        "    Nspectrenoyau=4*p+1\n",
        "    thetas,_=liste_thetas_depuis_spectre(Nspectrenoyau)\n",
        "    Nthetas=thetas.shape[0]\n",
        "    indexs,_,_=calcul_indices_passage_corr_power_spectrum_kernel(Nspectrenoyau,(Nthetas,4*p+1),thetas)\n",
        "    #calcul des autocorrelations de projections du gradient suivant theta\n",
        "    # sur l'axe theta\n",
        "    cinit=calcul_correlations_initiales(img,thetas,p)\n",
        "    # Deconvoluer légèrement les autocorrélations pour suppprimer un \n",
        "    # \"flou intrinsèque\n",
        "    cdeconv=deconv_intrinsic_blur(cinit)\n",
        "    # Calcul des supports initiaux\n",
        "    supports=initial_support_estimation(cdeconv,2*p,thetas,kappa=30)\n",
        "    # En déduire les autocorrélations puis le spectre de puissance de h\n",
        "    hpower=Estimate_h_correlations(cdeconv,supports)\n",
        "    H2=spectre_puissance_depuis_corrs(hpower,Nspectrenoyau,indexs)\n",
        "    if verbose:\n",
        "        affiche(fftshift(H2),titre='densite_spectrale_de_puissance')\n",
        "        g=SinglePhaseRetrieval(H2, p,Mh=Nspectrenoyau,Ninner=Ninner)\n",
        "        affiche(g,titre='premier_noyau_estime')\n",
        "        print('temps totale de la première phase', time.time()-t0)\n",
        "    # boucle pour affiner le noyau\n",
        "    # Seul le support induit par le noyau amélioré est utilisé. \n",
        "    # On suppose que trois itération de cette boucle suffisent pour atteindre \n",
        "    # l'optimum de ce que peut faire la méthode\n",
        "    # on va quand meme stocker tous les trois noyaux dans une liste\n",
        "    gbests=[]\n",
        "    for m in range(Nouter):\n",
        "        t0=time.time()\n",
        "        new_corrs=Estimate_h_correlations(cdeconv,supports)\n",
        "        H2=spectre_puissance_depuis_corrs(new_corrs,Nspectrenoyau,indexs)\n",
        "        cbest=None\n",
        "        P=Propose_patch_haute_variance(imgvars,img,taille_patch)\n",
        "        for k in range(Ntries):\n",
        "            if verbose:\n",
        "                print('boucle numéro',m, 'essai',k, 'sur ', Ntries)\n",
        "            g=SinglePhaseRetrieval(abs(H2)**0.5,p,Mh=Nspectrenoyau)\n",
        "            if (p//2)*2==p:\n",
        "                \n",
        "                gdeconv=np.zeros((p+1,p+1))\n",
        "                gdeconv[:p,:p]=g\n",
        "            else:\n",
        "                gdeconv=g\n",
        "                \n",
        "            tmpim=TVdeconv(P,gdeconv,lamb,nbit=40)\n",
        "            c=score_restau(tmpim)\n",
        "            \n",
        "            if verbose: \n",
        "                print('score',c)\n",
        "            if cbest is None or c<cbest:\n",
        "                gbest=g.copy()\n",
        "                cbest=c\n",
        "            g=np.fliplr(np.flipud(g))\n",
        "            if (p//2)*2==p:\n",
        "                gdeconv=np.zeros((p+1,p+1))\n",
        "                gdeconv[:p,:p]=g\n",
        "            else:\n",
        "                gdeconv=g\n",
        "    \n",
        "            tmpim=TVdeconv(P,gdeconv,lamb,nbit=40)\n",
        "            c=score_restau(tmpim)\n",
        "            if verbose: \n",
        "                print('score flip',c)\n",
        "            if c<cbest:\n",
        "                gbest=g.copy()\n",
        "                cbest=c\n",
        "        supports=Restimation_supports_noyau(gbest,p,thetas,ratio=0.05)\n",
        "        if verbose: \n",
        "            affiche(gbest,titre='tentative'+str(m))\n",
        "            print('temps total de la boucle numéro',m ,'est ',time.time()-t0)\n",
        "        gbests.append(gbest)\n",
        "    return gbest,gbests\n",
        "def centrer_le_noyau(K):\n",
        "    # opération optionnelle \n",
        "    p=K.shape[0]\n",
        "    assert p%2==1, 'Le noyau doit être de taille impaire'\n",
        "    X,Y= np.meshgrid(np.arange(p),np.arange(p))\n",
        "    xm=int(np.round((X*K).sum()))\n",
        "    ym=int(np.round((Y*K).sum()))\n",
        "    Knew=np.zeros(K.shape)\n",
        "    dx=min(p-1-xm,xm)\n",
        "    dy=min(p-1-ym,ym)\n",
        "    #print (xm,ym,dx,dy)\n",
        "    Knew[p//2-dy:p//2+dy+1,p//2-dx:p//2+dx+1]=K[ym-dy:ym+dy+1,xm-dx:xm+dx+1]\n",
        "    print('pourcentage de masse perdue', (1-Knew.sum()/K.sum())*100,'%')\n",
        "    Knew/=Knew.sum()\n",
        "    return Knew\n",
        "    \n",
        "    \n",
        "         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6gzTu18de3P"
      },
      "source": [
        "# Cellules pour tester la méthode en entier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS467AHyde3T"
      },
      "source": [
        "#%% PARTIE INTERACTIVE \n",
        "\n",
        "\n",
        "#%%\n",
        "im=read_image(rep_images+'taj_mahal.png')\n",
        "affiche(im)\n",
        "img,Cr,Cb=RGBtoYCrCb(im)\n",
        "\n",
        "noyau,tousnoyaux=estime_noyau(img)\n",
        "affiche(noyau, 'noyau_estime')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MvQKxNKfHcP"
      },
      "source": [
        "#%% utilisation du noyau\n",
        "t0=time.time()\n",
        "noyau_centre=centrer_le_noyau(noyau)\n",
        "img_deconv=TVdeconv(img,noyau_centre,2000/255)\n",
        "print('temps pour une déconvolution', time.time()-t0)\n",
        "img_deconv.clip(min=0,max=255,out=img_deconv) #couper les vlaeurs hors 0,255\n",
        "im_deconv_couleur=YCrCbtoRGB(img_deconv,Cr,Cb)\n",
        "affiche(im_deconv_couleur,'RESULT')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}