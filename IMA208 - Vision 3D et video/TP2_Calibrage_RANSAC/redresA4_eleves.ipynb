{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MqACDYJdVuy"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Feb  2 13:49:38 2022\n",
        "\n",
        "@author:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import imshow, show, subplot, title, axis, figure\n",
        "\n",
        "\n",
        "\n",
        "def warpImages(kp, img, M):\n",
        "\n",
        "    # Get size of the output image\n",
        "\n",
        "    h=kp[2].pt[1]\n",
        "    w=kp[2].pt[0]\n",
        "            \n",
        "    new_img = cv.warpPerspective(img, M,(np.int32(w),np.int32(h)))\n",
        "\n",
        "    return new_img\n",
        "\n",
        "\n",
        "def find_transformation(kpt1, kpt2, matches,transformatioo):\n",
        "    # Find an Homography matrix between two pictures\n",
        "    # Transforming keypoints to list of points\n",
        "   \n",
        "    dst_pts = np.float32([kpt1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "    src_pts = np.float32([kpt2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "\n",
        "\n",
        "    if transformation=='rigid':\n",
        "      print(transformation)\n",
        "\n",
        "      # Compute a rigid transformation (only scale + rotation + translation) \n",
        "    \n",
        "      M, mask = cv.estimateAffinePartial2D(src_pts, dst_pts)\n",
        "      print('mask : ' , mask)\n",
        "      print(M)\n",
        "      \n",
        "      # Add à third neutral line to make a 3x3 matrix\n",
        "      affine_row = [0, 0, 1]\n",
        "      M = np.vstack((M, affine_row))\n",
        "\n",
        "    elif transformation=='affine':\n",
        "      print(transformation)\n",
        "\n",
        "      # Compute affine transformation (6 parameters)\n",
        "\n",
        "      M, mask = cv.estimateAffine2D(src_pts, dst_pts) \n",
        "      print('mask : ' , mask)\n",
        "      print(M)\n",
        "      \n",
        "      # Add à third neutral line to make a 3x3 matrix\n",
        "      affine_row = [0, 0, 1]\n",
        "      M = np.vstack((M, affine_row))\n",
        "\n",
        "    elif transformation=='perspective':\n",
        "      print(transformation)\n",
        "      # Compute an homography (8 parameters)\n",
        "      M, mask = cv.findHomography(src_pts, dst_pts,cv.RANSAC,5)\n",
        "      print('mask : ' , mask)\n",
        "      print(M)\n",
        "\n",
        "    matchesMask = mask.ravel().tolist()\n",
        "    \n",
        "    return M,matchesMask\n",
        "\n",
        "\n",
        "# Read images\n",
        "img1c = cv.imread('hello.jpg', 1)\n",
        "img1 = cv.cvtColor(img1c, cv.COLOR_BGR2GRAY)\n",
        "img1c = cv.cvtColor(img1c, cv.COLOR_BGR2RGB)\n",
        "\n",
        "# Choix du modèle de transformation : 'rigid','affine' ou 'perspective'\n",
        "\n",
        "transformation='perspective'\n",
        "\n",
        "# Données pour l'image redressée au format A4\n",
        "resol=5\n",
        "x1=0\n",
        "y1=0\n",
        "sizeH=297\n",
        "sizeV=210\n",
        "x2=resol*sizeH\n",
        "y2=resol*sizeV\n",
        "\n",
        "pts1=[]\n",
        "pts1.append([x1,y1])\n",
        "pts1.append([x2,y1])\n",
        "pts1.append([x2,y2])\n",
        "pts1.append([x1,y2])\n",
        "\n",
        "# Deux outliers\n",
        "\n",
        "pts1.append([x2/2,y2/2])\n",
        "pts1.append([x1/2,y1/2])\n",
        "\n",
        "\n",
        "# données pour g4.jpg\n",
        "\n",
        "x1=2030\n",
        "y1=110\n",
        "x2=2750\n",
        "y2=904\n",
        "x3=920\n",
        "y3=1638\n",
        "x4=363\n",
        "y4=663\n",
        "\n",
        "\n",
        "# données pour f4.jpg\n",
        "\n",
        "x1=244\n",
        "y1=949\n",
        "x2=1450\n",
        "y2=924\n",
        "x3=1541\n",
        "y3=2592\n",
        "x4=225\n",
        "y4=2621\n",
        "\n",
        "\n",
        "# données pour hello.jpg\n",
        "\n",
        "x1=71\n",
        "y1=238\n",
        "x2=355\n",
        "y2=114\n",
        "x3=471\n",
        "y3=260\n",
        "x4=186\n",
        "y4=438\n",
        "\n",
        "\n",
        "# Deux outliers\n",
        "\n",
        "x5=(x1+x2)/2\n",
        "y5=(y3+y4)/4\n",
        "\n",
        "x6=(y1+y2)/2\n",
        "y6=(x2+x4)/3\n",
        "\n",
        "\n",
        "pts2=[]\n",
        "pts2.append([x1,y1])\n",
        "pts2.append([x2,y2])\n",
        "pts2.append([x3,y3])\n",
        "pts2.append([x4,y4])\n",
        "pts2.append([x5,y5])\n",
        "pts2.append([x6,y6])\n",
        "\n",
        "kp1 = [cv.KeyPoint(x[0], x[1], 1) for x in pts1]\n",
        "kp2 = [cv.KeyPoint(x[0], x[1], 1) for x in pts2]\n",
        "\n",
        "print('points feuille')\n",
        "for i in range (len(pts1)):\n",
        "    print(kp1[i].pt)\n",
        "\n",
        "print('points image')\n",
        "for i in range (len(pts2)):\n",
        "    print(kp2[i].pt)\n",
        "\n",
        "\n",
        "goodMatches=[]\n",
        "for i in range(len(pts1)):\n",
        "    m=cv.DMatch(i,i,0)\n",
        "    goodMatches.append(m)\n",
        "\n",
        "print('matchess')\n",
        "for m in goodMatches:\n",
        "    (x1, y1) = kp1[m.queryIdx].pt\n",
        "    (x2, y2) = kp2[m.trainIdx].pt\n",
        "    print ( x1,y1,x2,y2)\n",
        "\n",
        "kp_img = cv.drawKeypoints(img1, kp2, None, color=(255, 255, 0))\n",
        "figure(figsize=(10,10),dpi=100)\n",
        "imshow(kp_img)\n",
        "show()\n",
        "\n",
        "#\n",
        "## find transformation and compute perspective correction\n",
        "matrix1to2,mask = find_transformation(kp1, kp2,goodMatches,transformation)\n",
        "img1to2 = warpImages(kp1,img1c, matrix1to2)\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "print('mask :',mask)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Points d'appui utilisés"
      ],
      "metadata": {
        "id": "-eLbEgSqaWyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('mask :',mask)\n"
      ],
      "metadata": {
        "id": "Auh-Xci-atFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image redressée"
      ],
      "metadata": {
        "id": "hZMrocqia6IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "figure(figsize=(10,10),dpi=100)\n",
        "title=('image redressée')\n",
        "imshow(img1to2)\n",
        "show()\n",
        "\n"
      ],
      "metadata": {
        "id": "6UKEN6cYbLsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "redresA4_eleves.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}